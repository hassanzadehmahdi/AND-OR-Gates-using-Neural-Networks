# AND-OR-Gates-using-Neural-Networks
In this project, we used Hebbian, Perceptron and Adaline neural networks to implement AND gate, and OR gate.

### Hebbian
Hebbian Learning Rule, also known as Hebb Learning Rule, was proposed by Donald O Hebb. It is one of the first and also easiest learning rules in the neural network. It is used for pattern classification. It is a single layer neural network, i.e. it has one input layer and one output layer. The input layer can have many units, say n. The output layer only has one unit. Hebbian rule works by updating the weights between neurons in the neural network for each training sample.

### Perceptron
In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class. It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. 

### Adaline
Adline stands for adaptive linear neuron. It makes use of linear activation function, and it uses the delta rule for training to minimize the mean squared errors between the actual output and the desired target output. The weights and bias are adjustable. Here, we perform 10 epochs of training.

An example of running the program:

![jj](https://user-images.githubusercontent.com/45950266/153374433-d75b8095-d665-49b6-a939-946e2aa54976.png)
